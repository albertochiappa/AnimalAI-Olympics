{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "accepted-warner",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_example\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buried-aggregate",
   "metadata": {},
   "source": [
    "## Checking that everything works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "improved-attention",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"adversarial-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "coupled-xerox",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(state):\n",
    "    fig = plt.imshow(state, cmap=plt.get_cmap('Accent'))\n",
    "    # values\n",
    "    values = np.array([0, 1, 2, 3])\n",
    "    #items\n",
    "    items = ['Arena', 'Agent', 'Goal', 'Wall']\n",
    "    # colormap used by imshow\n",
    "    colors = [fig.cmap(fig.norm(value)) for value in values]\n",
    "    # create a patch (proxy artist) for every color \n",
    "    patches = [mpatches.Patch(color=colors[i], label=\"{l}\".format(l=items[i]) ) for i in range(len(values)) ]\n",
    "    # put those patched as legend-handles into the legend\n",
    "    plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0. )\n",
    "\n",
    "    plt.grid(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "potential-making",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_one_episode(env, verbose=False):\n",
    "    env.reset()\n",
    "    sum_reward = 0\n",
    "\n",
    "    for i in range(env.MAX_STEPS+1):\n",
    "        action = env.action_space.sample()\n",
    "        if verbose:\n",
    "            print(\"action:\", action)\n",
    "        state, reward, done, info = env.step(action)\n",
    "        sum_reward += reward\n",
    "\n",
    "        if verbose:\n",
    "            env.render()\n",
    "\n",
    "        if done:\n",
    "            if verbose:\n",
    "                print(\"done @ step {}\".format(i))\n",
    "            break\n",
    "\n",
    "    if verbose:\n",
    "        print(\"cumulative reward\", sum_reward)\n",
    "\n",
    "    return sum_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "curious-lincoln",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum reward:  -10\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make(\"adversarial-v1\")\n",
    "sum_reward = run_one_episode(env)\n",
    "print('Sum reward: ', sum_reward)\n",
    "\n",
    "#visualize(env.state) --> if adversarial_v0\n",
    "\n",
    "visualize(env.image_space) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bacterial-desktop",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'image': array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  'time_step': [2]},\n",
       " 0,\n",
       " False,\n",
       " {})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make(\"adversarial-v1\")\n",
    "env.step(0)\n",
    "env.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "excellent-purchase",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "baseline cumulative reward: -1e+01\n"
     ]
    }
   ],
   "source": [
    "history = []\n",
    "\n",
    "for _ in range(10):\n",
    "    sum_reward = run_one_episode(env, verbose=False)\n",
    "    history.append(sum_reward)\n",
    "\n",
    "avg_sum_reward = sum(history) / len(history)\n",
    "print(\"\\nbaseline cumulative reward: {:6.2}\".format(avg_sum_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fourth-comedy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-10, -10, -10, -10, -10, -10, -10, -10, -10, -10]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strong-restaurant",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "Initialize the directory in which to save checkpoints (i.e., serialize a policy to disk) as a subdirectory ./tmp/exa and also the directory in which to write the logs which Ray expects to be at ~/ray_results/ by default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "satisfied-istanbul",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "chkpt_root = \"tmp/exa\"\n",
    "\n",
    "shutil.rmtree(chkpt_root, ignore_errors=True, onerror=None)\n",
    "ray_results = \"{}/ray_results/\".format(os.getenv(\"HOME\"))\n",
    "shutil.rmtree(ray_results, ignore_errors=True, onerror=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-envelope",
   "metadata": {},
   "source": [
    "We’ll start Ray running in local mode, i.e., not running on a remote cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "attached-blanket",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-29 17:16:38,845\tINFO services.py:1174 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.1.48',\n",
       " 'raylet_ip_address': '192.168.1.48',\n",
       " 'redis_address': '192.168.1.48:24330',\n",
       " 'object_store_address': '/tmp/ray/session_2021-03-29_17-16-38_219559_12194/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2021-03-29_17-16-38_219559_12194/sockets/raylet',\n",
       " 'webui_url': '127.0.0.1:8266',\n",
       " 'session_dir': '/tmp/ray/session_2021-03-29_17-16-38_219559_12194',\n",
       " 'metrics_export_port': 49456,\n",
       " 'node_id': '509f22d0368e8a3f1b0951facf023aab77b17b6c3975488f1bfb26d8'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "ray.init(ignore_reinit_error=True, local_mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grateful-pasta",
   "metadata": {},
   "source": [
    "Register our environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "great-migration",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune.registry import register_env\n",
    "from gym_example.envs.adversarial_v1 import Adversarial_v1\n",
    "\n",
    "select_env = \"adversarial-v1\"\n",
    "register_env(select_env, lambda config: Adversarial_v1())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-anxiety",
   "metadata": {},
   "source": [
    "Next we’ll configure the environment to use proximal policy optimization (PPO) and create an agent to train using RLlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "successful-forge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/psanchezlopez/anaconda3/envs/animalai/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-29 17:16:44,763\tINFO trainer.py:616 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
      "2021-03-29 17:16:44,763\tINFO trainer.py:643 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "2021-03-29 17:16:44,818\tWARNING deprecation.py:34 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/psanchezlopez/anaconda3/envs/animalai/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/psanchezlopez/anaconda3/envs/animalai/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-29 17:16:46,010\tWARNING deprecation.py:34 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "2021-03-29 17:16:46,956\tWARNING deprecation.py:34 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "2021-03-29 17:16:49,546\tWARNING util.py:47 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "import ray.rllib.agents.ppo as ppo\n",
    "\n",
    "config = ppo.DEFAULT_CONFIG.copy()\n",
    "\n",
    "config[\"log_level\"] = \"WARN\"\n",
    "agent = ppo.PPOTrainer(config, env=select_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "curious-shape",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_workers': 2,\n",
       " 'num_envs_per_worker': 1,\n",
       " 'create_env_on_driver': False,\n",
       " 'rollout_fragment_length': 200,\n",
       " 'batch_mode': 'truncate_episodes',\n",
       " 'num_gpus': 0,\n",
       " 'train_batch_size': 4000,\n",
       " 'model': {'fcnet_hiddens': [256, 256],\n",
       "  'fcnet_activation': 'tanh',\n",
       "  'conv_filters': None,\n",
       "  'conv_activation': 'relu',\n",
       "  'free_log_std': False,\n",
       "  'no_final_linear': False,\n",
       "  'vf_share_layers': False,\n",
       "  'use_lstm': False,\n",
       "  'max_seq_len': 20,\n",
       "  'lstm_cell_size': 256,\n",
       "  'lstm_use_prev_action': False,\n",
       "  'lstm_use_prev_reward': False,\n",
       "  '_time_major': False,\n",
       "  'use_attention': False,\n",
       "  'attention_num_transformer_units': 1,\n",
       "  'attention_dim': 64,\n",
       "  'attention_num_heads': 1,\n",
       "  'attention_head_dim': 32,\n",
       "  'attention_memory_inference': 50,\n",
       "  'attention_memory_training': 50,\n",
       "  'attention_position_wise_mlp_dim': 32,\n",
       "  'attention_init_gru_gate_bias': 2.0,\n",
       "  'num_framestacks': 'auto',\n",
       "  'dim': 84,\n",
       "  'grayscale': False,\n",
       "  'zero_mean': True,\n",
       "  'custom_model': None,\n",
       "  'custom_model_config': {},\n",
       "  'custom_action_dist': None,\n",
       "  'custom_preprocessor': None,\n",
       "  'lstm_use_prev_action_reward': -1,\n",
       "  'framestack': True},\n",
       " 'optimizer': {},\n",
       " 'gamma': 0.99,\n",
       " 'horizon': None,\n",
       " 'soft_horizon': False,\n",
       " 'no_done_at_end': False,\n",
       " 'env_config': {},\n",
       " 'env': None,\n",
       " 'normalize_actions': False,\n",
       " 'clip_rewards': None,\n",
       " 'clip_actions': True,\n",
       " 'preprocessor_pref': 'deepmind',\n",
       " 'lr': 5e-05,\n",
       " 'monitor': False,\n",
       " 'log_level': 'WARN',\n",
       " 'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       " 'ignore_worker_failures': False,\n",
       " 'log_sys_usage': True,\n",
       " 'fake_sampler': False,\n",
       " 'framework': 'tf',\n",
       " 'eager_tracing': False,\n",
       " 'explore': True,\n",
       " 'exploration_config': {'type': 'StochasticSampling'},\n",
       " 'evaluation_interval': None,\n",
       " 'evaluation_num_episodes': 10,\n",
       " 'in_evaluation': False,\n",
       " 'evaluation_config': {},\n",
       " 'evaluation_num_workers': 0,\n",
       " 'custom_eval_function': None,\n",
       " 'sample_async': False,\n",
       " '_use_trajectory_view_api': True,\n",
       " 'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       " 'observation_filter': 'NoFilter',\n",
       " 'synchronize_filters': True,\n",
       " 'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "  'inter_op_parallelism_threads': 2,\n",
       "  'gpu_options': {'allow_growth': True},\n",
       "  'log_device_placement': False,\n",
       "  'device_count': {'CPU': 1},\n",
       "  'allow_soft_placement': True},\n",
       " 'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "  'inter_op_parallelism_threads': 8},\n",
       " 'compress_observations': False,\n",
       " 'collect_metrics_timeout': 180,\n",
       " 'metrics_smoothing_episodes': 100,\n",
       " 'remote_worker_envs': False,\n",
       " 'remote_env_batch_wait_ms': 0,\n",
       " 'min_iter_time_s': 0,\n",
       " 'timesteps_per_iteration': 0,\n",
       " 'seed': None,\n",
       " 'extra_python_environs_for_driver': {},\n",
       " 'extra_python_environs_for_worker': {},\n",
       " 'num_cpus_per_worker': 1,\n",
       " 'num_gpus_per_worker': 0,\n",
       " 'custom_resources_per_worker': {},\n",
       " 'num_cpus_for_driver': 1,\n",
       " 'memory': 0,\n",
       " 'object_store_memory': 0,\n",
       " 'memory_per_worker': 0,\n",
       " 'object_store_memory_per_worker': 0,\n",
       " 'input': 'sampler',\n",
       " 'input_evaluation': ['is', 'wis'],\n",
       " 'postprocess_inputs': False,\n",
       " 'shuffle_buffer_size': 0,\n",
       " 'output': None,\n",
       " 'output_compress_columns': ['obs', 'new_obs'],\n",
       " 'output_max_file_size': 67108864,\n",
       " 'multiagent': {'policies': {},\n",
       "  'policy_mapping_fn': None,\n",
       "  'policies_to_train': None,\n",
       "  'observation_fn': None,\n",
       "  'replay_mode': 'independent',\n",
       "  'count_steps_by': 'env_steps'},\n",
       " 'logger_config': None,\n",
       " 'replay_sequence_length': 1,\n",
       " 'use_critic': True,\n",
       " 'use_gae': True,\n",
       " 'lambda': 1.0,\n",
       " 'kl_coeff': 0.2,\n",
       " 'sgd_minibatch_size': 128,\n",
       " 'shuffle_sequences': True,\n",
       " 'num_sgd_iter': 30,\n",
       " 'lr_schedule': None,\n",
       " 'vf_loss_coeff': 1.0,\n",
       " 'entropy_coeff': 0.0,\n",
       " 'entropy_coeff_schedule': None,\n",
       " 'clip_param': 0.3,\n",
       " 'vf_clip_param': 10.0,\n",
       " 'grad_clip': None,\n",
       " 'kl_target': 0.01,\n",
       " 'simple_optimizer': False,\n",
       " '_fake_gpus': False,\n",
       " 'vf_share_layers': -1}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppo.DEFAULT_CONFIG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-france",
   "metadata": {},
   "source": [
    "For each iteration, we call result = agent.train() to run the episodes, and then call chkpt_file = agent.save(chkpt_root) to save a checkpoint of the latest policy. Then we print metrics that show how well the learning has progressed. The resulting output should look close to the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "certified-petroleum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1 reward -10.00/ -3.40/100.00 len 53.00 saved tmp/exa/checkpoint_3/checkpoint-3\n",
      " 2 reward -10.00/ -4.50/100.00 len 53.00 saved tmp/exa/checkpoint_4/checkpoint-4\n",
      " 3 reward -10.00/ -3.40/100.00 len 53.00 saved tmp/exa/checkpoint_5/checkpoint-5\n",
      " 4 reward -10.00/ -5.60/100.00 len 53.00 saved tmp/exa/checkpoint_6/checkpoint-6\n",
      " 5 reward -10.00/ -8.90/100.00 len 53.00 saved tmp/exa/checkpoint_7/checkpoint-7\n",
      " 6 reward -10.00/ -8.90/100.00 len 53.00 saved tmp/exa/checkpoint_8/checkpoint-8\n",
      " 7 reward -10.00/ -6.70/100.00 len 53.00 saved tmp/exa/checkpoint_9/checkpoint-9\n",
      " 8 reward -10.00/ -4.50/100.00 len 53.00 saved tmp/exa/checkpoint_10/checkpoint-10\n",
      " 9 reward -10.00/ -3.40/100.00 len 53.00 saved tmp/exa/checkpoint_11/checkpoint-11\n",
      "10 reward -10.00/ -5.60/100.00 len 53.00 saved tmp/exa/checkpoint_12/checkpoint-12\n",
      "11 reward -10.00/ -6.70/100.00 len 53.00 saved tmp/exa/checkpoint_13/checkpoint-13\n",
      "12 reward -10.00/ -6.70/100.00 len 53.00 saved tmp/exa/checkpoint_14/checkpoint-14\n",
      "13 reward -10.00/ -8.90/100.00 len 53.00 saved tmp/exa/checkpoint_15/checkpoint-15\n",
      "14 reward -10.00/ -4.50/100.00 len 53.00 saved tmp/exa/checkpoint_16/checkpoint-16\n",
      "15 reward -10.00/ -2.30/100.00 len 53.00 saved tmp/exa/checkpoint_17/checkpoint-17\n",
      "16 reward -10.00/ -1.20/100.00 len 53.00 saved tmp/exa/checkpoint_18/checkpoint-18\n",
      "17 reward -10.00/ -4.50/100.00 len 53.00 saved tmp/exa/checkpoint_19/checkpoint-19\n",
      "18 reward -10.00/  1.00/100.00 len 53.00 saved tmp/exa/checkpoint_20/checkpoint-20\n",
      "19 reward -10.00/ -6.70/100.00 len 53.00 saved tmp/exa/checkpoint_21/checkpoint-21\n",
      "20 reward -10.00/ -7.80/100.00 len 53.00 saved tmp/exa/checkpoint_22/checkpoint-22\n",
      "21 reward -10.00/ -3.40/100.00 len 53.00 saved tmp/exa/checkpoint_23/checkpoint-23\n",
      "22 reward -10.00/ -5.60/100.00 len 53.00 saved tmp/exa/checkpoint_24/checkpoint-24\n",
      "23 reward -10.00/ -3.40/100.00 len 53.00 saved tmp/exa/checkpoint_25/checkpoint-25\n",
      "24 reward -10.00/ -5.60/100.00 len 53.00 saved tmp/exa/checkpoint_26/checkpoint-26\n",
      "25 reward -10.00/ -4.50/100.00 len 53.00 saved tmp/exa/checkpoint_27/checkpoint-27\n",
      "26 reward -10.00/  1.00/100.00 len 53.00 saved tmp/exa/checkpoint_28/checkpoint-28\n",
      "27 reward -10.00/ -4.50/100.00 len 53.00 saved tmp/exa/checkpoint_29/checkpoint-29\n",
      "28 reward -10.00/ -6.70/100.00 len 53.00 saved tmp/exa/checkpoint_30/checkpoint-30\n",
      "29 reward -10.00/ -1.20/100.00 len 53.00 saved tmp/exa/checkpoint_31/checkpoint-31\n",
      "30 reward -10.00/ -5.60/100.00 len 53.00 saved tmp/exa/checkpoint_32/checkpoint-32\n",
      "31 reward -10.00/ -1.20/100.00 len 53.00 saved tmp/exa/checkpoint_33/checkpoint-33\n",
      "32 reward -10.00/ -6.70/100.00 len 53.00 saved tmp/exa/checkpoint_34/checkpoint-34\n",
      "33 reward -10.00/ -5.60/100.00 len 53.00 saved tmp/exa/checkpoint_35/checkpoint-35\n",
      "34 reward -10.00/ -7.80/100.00 len 53.00 saved tmp/exa/checkpoint_36/checkpoint-36\n",
      "35 reward -10.00/ -6.70/100.00 len 53.00 saved tmp/exa/checkpoint_37/checkpoint-37\n",
      "36 reward -10.00/ -4.50/100.00 len 53.00 saved tmp/exa/checkpoint_38/checkpoint-38\n",
      "37 reward -10.00/ -2.30/100.00 len 53.00 saved tmp/exa/checkpoint_39/checkpoint-39\n",
      "38 reward -10.00/ -7.80/100.00 len 53.00 saved tmp/exa/checkpoint_40/checkpoint-40\n",
      "39 reward -10.00/ -6.70/100.00 len 53.00 saved tmp/exa/checkpoint_41/checkpoint-41\n",
      "40 reward -10.00/ -8.90/100.00 len 53.00 saved tmp/exa/checkpoint_42/checkpoint-42\n",
      "41 reward -10.00/ -6.70/100.00 len 53.00 saved tmp/exa/checkpoint_43/checkpoint-43\n",
      "42 reward -10.00/ -5.60/100.00 len 53.00 saved tmp/exa/checkpoint_44/checkpoint-44\n",
      "43 reward -10.00/ -4.50/100.00 len 53.00 saved tmp/exa/checkpoint_45/checkpoint-45\n",
      "44 reward -10.00/ -3.40/100.00 len 53.00 saved tmp/exa/checkpoint_46/checkpoint-46\n",
      "45 reward -10.00/ -4.50/100.00 len 53.00 saved tmp/exa/checkpoint_47/checkpoint-47\n",
      "46 reward -10.00/ -4.50/100.00 len 53.00 saved tmp/exa/checkpoint_48/checkpoint-48\n",
      "47 reward -10.00/ -3.40/100.00 len 53.00 saved tmp/exa/checkpoint_49/checkpoint-49\n",
      "48 reward -10.00/ -6.70/100.00 len 53.00 saved tmp/exa/checkpoint_50/checkpoint-50\n",
      "49 reward -10.00/ -2.30/100.00 len 53.00 saved tmp/exa/checkpoint_51/checkpoint-51\n",
      "50 reward -10.00/ -2.30/100.00 len 53.00 saved tmp/exa/checkpoint_52/checkpoint-52\n",
      "51 reward -10.00/ -5.60/100.00 len 53.00 saved tmp/exa/checkpoint_53/checkpoint-53\n",
      "52 reward -10.00/ -6.70/100.00 len 53.00 saved tmp/exa/checkpoint_54/checkpoint-54\n",
      "53 reward -10.00/ -3.40/100.00 len 53.00 saved tmp/exa/checkpoint_55/checkpoint-55\n",
      "54 reward -10.00/ -6.70/100.00 len 53.00 saved tmp/exa/checkpoint_56/checkpoint-56\n",
      "55 reward -10.00/ -1.20/100.00 len 53.00 saved tmp/exa/checkpoint_57/checkpoint-57\n",
      "56 reward -10.00/ -3.40/100.00 len 53.00 saved tmp/exa/checkpoint_58/checkpoint-58\n",
      "57 reward -10.00/ -5.60/100.00 len 53.00 saved tmp/exa/checkpoint_59/checkpoint-59\n",
      "58 reward -10.00/ -5.60/100.00 len 53.00 saved tmp/exa/checkpoint_60/checkpoint-60\n",
      "59 reward -10.00/ -0.10/100.00 len 53.00 saved tmp/exa/checkpoint_61/checkpoint-61\n",
      "60 reward -10.00/ -2.30/100.00 len 53.00 saved tmp/exa/checkpoint_62/checkpoint-62\n",
      "61 reward -10.00/ -8.90/100.00 len 53.00 saved tmp/exa/checkpoint_63/checkpoint-63\n",
      "62 reward -10.00/ -5.60/100.00 len 53.00 saved tmp/exa/checkpoint_64/checkpoint-64\n",
      "63 reward -10.00/ -4.50/100.00 len 53.00 saved tmp/exa/checkpoint_65/checkpoint-65\n",
      "64 reward -10.00/ -2.30/100.00 len 53.00 saved tmp/exa/checkpoint_66/checkpoint-66\n",
      "65 reward -10.00/ -5.60/100.00 len 53.00 saved tmp/exa/checkpoint_67/checkpoint-67\n",
      "66 reward -10.00/ -6.70/100.00 len 53.00 saved tmp/exa/checkpoint_68/checkpoint-68\n"
     ]
    },
    {
     "ename": "RayTaskError",
     "evalue": "\u001b[36mray::RolloutWorker.par_iter_next()\u001b[39m (pid=12194, ip=192.168.1.48)\n  File \"python/ray/_raylet.pyx\", line 432, in ray._raylet.execute_task.function_executor\n  File \"/home/psanchezlopez/anaconda3/envs/animalai/lib/python3.7/site-packages/ray/util/iter.py\", line 1152, in par_iter_next\n    return next(self.local_it)\n  File \"/home/psanchezlopez/anaconda3/envs/animalai/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 327, in gen_rollouts\n    yield self.sample()\n  File \"/home/psanchezlopez/anaconda3/envs/animalai/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 662, in sample\n    batches = [self.input_reader.next()]\n  File \"/home/psanchezlopez/anaconda3/envs/animalai/lib/python3.7/site-packages/ray/rllib/evaluation/sampler.py\", line 95, in next\n    batches = [self.get_data()]\n  File \"/home/psanchezlopez/anaconda3/envs/animalai/lib/python3.7/site-packages/ray/rllib/evaluation/sampler.py\", line 224, in get_data\n    item = next(self.rollout_provider)\n  File \"/home/psanchezlopez/anaconda3/envs/animalai/lib/python3.7/site-packages/ray/rllib/evaluation/sampler.py\", line 656, in _env_runner\n    tf_sess=tf_sess,\n  File \"/home/psanchezlopez/anaconda3/envs/animalai/lib/python3.7/site-packages/ray/rllib/evaluation/sampler.py\", line 1344, in _do_policy_eval_w_trajectory_view_api\n    episodes=[active_episodes[t.env_id] for t in eval_data])\n  File \"/home/psanchezlopez/anaconda3/envs/animalai/lib/python3.7/site-packages/ray/rllib/policy/tf_policy.py\", line 367, in compute_actions_from_input_dict\n    fetched = builder.get(to_fetch)\n  File \"/home/psanchezlopez/anaconda3/envs/animalai/lib/python3.7/site-packages/ray/rllib/utils/tf_run_builder.py\", line 44, in get\n    self.feed_dict, os.environ.get(\"TF_TIMELINE_DIR\"))\n  File \"/home/psanchezlopez/anaconda3/envs/animalai/lib/python3.7/site-packages/ray/rllib/utils/tf_run_builder.py\", line 89, in run_timeline\n    fetches = sess.run(ops, feed_dict=feed_dict)\n  File \"/home/psanchezlopez/anaconda3/envs/animalai/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 956, in run\n    run_metadata_ptr)\n  File \"/home/psanchezlopez/anaconda3/envs/animalai/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1152, in _run\n    not subfeed_t.get_shape().is_compatible_with(np_val.shape)):\n  File \"/home/psanchezlopez/anaconda3/envs/animalai/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_shape.py\", line 1055, in is_compatible_with\n    def is_compatible_with(self, other):\nKeyboardInterrupt\n\nDuring handling of the above exception, another exception occurred:\n\n\u001b[36mray::RolloutWorker.par_iter_next()\u001b[39m (pid=12194, ip=192.168.1.48)\n  File \"python/ray/_raylet.pyx\", line 473, in ray._raylet.execute_task\n  File \"python/ray/_raylet.pyx\", line 497, in ray._raylet.execute_task\nray.exceptions.TaskCancelledError: Task: TaskID(ffffffffffffffffffffffffffffffffffffffff01000000) was cancelled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRayTaskError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-10eb8ea6797e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mchkpt_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchkpt_root\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     print(status.format(\n",
      "\u001b[0;32m~/anaconda3/envs/animalai/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    524\u001b[0m                         \u001b[0;34m\"continue training without the failed worker, set \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                         \"`'ignore_worker_failures': True`.\")\n\u001b[0;32m--> 526\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# allow logs messages to propagate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/animalai/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mMAX_WORKER_FAILURE_RETRIES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mRayError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ignore_worker_failures\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/animalai/lib/python3.7/site-packages/ray/tune/trainable.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    224\u001b[0m         \"\"\"\n\u001b[1;32m    225\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"step() needs to return a dict.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/animalai/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_exec_impl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;31m# self._iteration gets incremented after this function returns,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/animalai/lib/python3.7/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    754\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/animalai/lib/python3.7/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mapply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mapply_foreach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/animalai/lib/python3.7/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mapply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mapply_foreach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/animalai/lib/python3.7/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mapply_filter\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    841\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"LocalIterator[T]\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mapply_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metrics_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/animalai/lib/python3.7/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mapply_filter\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    841\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"LocalIterator[T]\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mapply_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metrics_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/animalai/lib/python3.7/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mapply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mapply_foreach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/animalai/lib/python3.7/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mapply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mapply_foreach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/animalai/lib/python3.7/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mapply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mapply_foreach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/animalai/lib/python3.7/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mapply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mapply_foreach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/animalai/lib/python3.7/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mapply_flatten\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    874\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"LocalIterator[T[0]]\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mapply_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    877\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/animalai/lib/python3.7/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36madd_wait_hooks\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    826\u001b[0m                             \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_fetch_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m                         \u001b[0mnew_item\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m                     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m                         \u001b[0mnew_item\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/animalai/lib/python3.7/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mapply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mapply_foreach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/animalai/lib/python3.7/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mapply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mapply_foreach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/animalai/lib/python3.7/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mapply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mapply_foreach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/animalai/lib/python3.7/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mapply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mapply_foreach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/animalai/lib/python3.7/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mbase_iterator\u001b[0;34m(timeout)\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mactive\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m                     \u001b[0;32myield\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m                     \u001b[0mfutures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpar_iter_next\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactive\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m                     \u001b[0;31m# Always yield after each round of gets with timeout.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/animalai/lib/python3.7/site-packages/ray/_private/client_mode_hook.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclient_mode_enabled\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_client_hook_enabled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/animalai/lib/python3.7/site-packages/ray/worker.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(object_refs, timeout)\u001b[0m\n\u001b[1;32m   1454\u001b[0m                     \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore_worker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump_object_store_memory_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1455\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRayTaskError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1456\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_instanceof_cause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1457\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1458\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRayTaskError\u001b[0m: \u001b[36mray::RolloutWorker.par_iter_next()\u001b[39m (pid=12194, ip=192.168.1.48)\n  File \"python/ray/_raylet.pyx\", line 432, in ray._raylet.execute_task.function_executor\n  File \"/home/psanchezlopez/anaconda3/envs/animalai/lib/python3.7/site-packages/ray/util/iter.py\", line 1152, in par_iter_next\n    return next(self.local_it)\n  File \"/home/psanchezlopez/anaconda3/envs/animalai/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 327, in gen_rollouts\n    yield self.sample()\n  File \"/home/psanchezlopez/anaconda3/envs/animalai/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 662, in sample\n    batches = [self.input_reader.next()]\n  File \"/home/psanchezlopez/anaconda3/envs/animalai/lib/python3.7/site-packages/ray/rllib/evaluation/sampler.py\", line 95, in next\n    batches = [self.get_data()]\n  File \"/home/psanchezlopez/anaconda3/envs/animalai/lib/python3.7/site-packages/ray/rllib/evaluation/sampler.py\", line 224, in get_data\n    item = next(self.rollout_provider)\n  File \"/home/psanchezlopez/anaconda3/envs/animalai/lib/python3.7/site-packages/ray/rllib/evaluation/sampler.py\", line 656, in _env_runner\n    tf_sess=tf_sess,\n  File \"/home/psanchezlopez/anaconda3/envs/animalai/lib/python3.7/site-packages/ray/rllib/evaluation/sampler.py\", line 1344, in _do_policy_eval_w_trajectory_view_api\n    episodes=[active_episodes[t.env_id] for t in eval_data])\n  File \"/home/psanchezlopez/anaconda3/envs/animalai/lib/python3.7/site-packages/ray/rllib/policy/tf_policy.py\", line 367, in compute_actions_from_input_dict\n    fetched = builder.get(to_fetch)\n  File \"/home/psanchezlopez/anaconda3/envs/animalai/lib/python3.7/site-packages/ray/rllib/utils/tf_run_builder.py\", line 44, in get\n    self.feed_dict, os.environ.get(\"TF_TIMELINE_DIR\"))\n  File \"/home/psanchezlopez/anaconda3/envs/animalai/lib/python3.7/site-packages/ray/rllib/utils/tf_run_builder.py\", line 89, in run_timeline\n    fetches = sess.run(ops, feed_dict=feed_dict)\n  File \"/home/psanchezlopez/anaconda3/envs/animalai/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 956, in run\n    run_metadata_ptr)\n  File \"/home/psanchezlopez/anaconda3/envs/animalai/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1152, in _run\n    not subfeed_t.get_shape().is_compatible_with(np_val.shape)):\n  File \"/home/psanchezlopez/anaconda3/envs/animalai/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_shape.py\", line 1055, in is_compatible_with\n    def is_compatible_with(self, other):\nKeyboardInterrupt\n\nDuring handling of the above exception, another exception occurred:\n\n\u001b[36mray::RolloutWorker.par_iter_next()\u001b[39m (pid=12194, ip=192.168.1.48)\n  File \"python/ray/_raylet.pyx\", line 473, in ray._raylet.execute_task\n  File \"python/ray/_raylet.pyx\", line 497, in ray._raylet.execute_task\nray.exceptions.TaskCancelledError: Task: TaskID(ffffffffffffffffffffffffffffffffffffffff01000000) was cancelled"
     ]
    }
   ],
   "source": [
    "status = \"{:2d} reward {:6.2f}/{:6.2f}/{:6.2f} len {:4.2f} saved {}\"\n",
    "n_iter = 100\n",
    "for n in range(n_iter):\n",
    "    result = agent.train()\n",
    "    chkpt_file = agent.save(chkpt_root)\n",
    "    print(status.format(\n",
    "            n + 1,\n",
    "            result[\"episode_reward_min\"],\n",
    "            result[\"episode_reward_mean\"],\n",
    "            result[\"episode_reward_max\"],\n",
    "            result[\"episode_len_mean\"],\n",
    "            chkpt_file\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-antenna",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
